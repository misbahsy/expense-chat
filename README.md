# Expense Chat

This is an [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app). Expense Chat allows you to upload and analyze your expense documents seamlessly, integrating with powerful APIs to provide insightful discussions.

## Getting Started

Follow these steps to set up and run the project locally.

### Prerequisites

- [Node.js](https://nodejs.org/) (v14 or later)
- [npm](https://www.npmjs.com/) or [yarn](https://yarnpkg.com/)
- [Langflow API Key](https://astra.datastax.com/) from Astra Datastax, free to use
- [OpenAI API Key](https://openai.com)

### Installation

1. **Clone the repository:**

   ```bash
   git clone https://github.com/your-username/expense-chat.git
   cd expense-chat
   ```

2. **Install dependencies:**

   Using npm:
   
   ```bash
   npm install
   ```
   
   Or using yarn:
   
   ```bash
   yarn
   ```

### Configuration

1. **Create a `.env` file in the root directory:**

   ```bash
   cp .env.example .env
   ```

2. **Set up environment variables in `.env`:**

   ```env
   DATABASE_URL="file:./prisma/dev.db"
   OPENAI_API_KEY="your-openai-api-key"
   LANGFLOW_API_KEY="your-langflow-api-key"
   ```

   - **`OPENAI_API_KEY`**: Obtain from [OpenAI](https://openai.com).
   - **`LANGFLOW_API_KEY`**: Obtain from [Astra Datastax](https://astra.datastax.com/), free to use.

### Running the Development Server

Start the development server:

Using npm:
```bash
npm run dev
```

Or using yarn:
```bash
yarn dev
```

Or using pnpm:
```bash
pnpm dev
```

Or using bun:
```bash
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the application in action.

### Building for Production

To build the application for production, run:

```bash
npm run build
```

Then start the production server:

```bash
npm start
```

## Features

- **Upload Documents:** Easily upload PDF documents for analysis.
- **OCR Processing:** Extract text from uploaded documents using OCR, generated by Zerox using LLM.
- **Chat Interface:** Interact with your data through a dynamic chat interface.
- **API Integration:** Seamlessly integrates with OpenAI and Langflow APIs for enhanced functionality.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - Learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - An interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.
```
